{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Splits\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyBigWig\n",
    "\n",
    "NARROWPEAK_SCHEMA = [\"chr\", \"start\", \"end\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"summit\"]\n",
    "\n",
    "peak_regions_df = pd.read_csv(\"/mnt/lab_data2/vir/tf_chr_atlas/temp/docker_modelling/ENCSR142IGM_peaks_inliers.bed.gz\", sep='\\t', names=NARROWPEAK_SCHEMA)\n",
    "peak_regions_df['group']='peak'\n",
    "peak_regions_df['ind']=range(len(peak_regions_df))\n",
    "nonpeak_regions_df = pd.read_csv(\"/mnt/lab_data2/vir/tf_chr_atlas/temp/docker_modelling/ENCSR142IGM_gc_neg_only.bed.gz\", sep='\\t', names=NARROWPEAK_SCHEMA)\n",
    "nonpeak_regions_df['group']='nonpeak'\n",
    "nonpeak_regions_df['ind']=range(len(nonpeak_regions_df))\n",
    "\n",
    "\n",
    "all_regions_df = pd.concat([peak_regions_df,nonpeak_regions_df])\n",
    "all_regions_df['pos']=all_regions_df['start']+all_regions_df['summit']\n",
    "all_regions_df.sort_values(by=['chr', 'pos'], inplace=True)\n",
    "all_regions_df=all_regions_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Creating Splits\")\n",
    "\n",
    "group_dict = {}\n",
    "\n",
    "inputlen=2114\n",
    "max_jitter=32\n",
    "\n",
    "cur_chrom = ''\n",
    "cur_group = ''\n",
    "last_pos = 0\n",
    "for index,row in all_regions_df.iterrows():\n",
    "    if cur_chrom != '':\n",
    "        if row['chr'] != cur_chrom:\n",
    "            cur_chrom = row['chr']\n",
    "            cur_group += 1\n",
    "            group_dict[cur_group] = [row]\n",
    "        else:\n",
    "            if row['pos'] <= int(last_pos) + int(inputlen) + int(2 * max_jitter):\n",
    "                group_dict[cur_group].append(row)\n",
    "            else:\n",
    "                cur_group += 1\n",
    "                group_dict[cur_group] = [row]\n",
    "    else:\n",
    "        cur_chrom = row['chr']\n",
    "        cur_group = 0\n",
    "        group_dict[cur_group] = [row]\n",
    "    last_pos = row['pos']\n",
    "    \n",
    "groups = []\n",
    "group_counts = []\n",
    "bigwig = '/mnt/lab_data2/vir/tf_chr_atlas/temp/docker_modelling/ENCSR142IGM_plus.bigWig'\n",
    "bw = pyBigWig.open(bigwig)\n",
    "\n",
    "for group in group_dict:\n",
    "    groups.append(group)\n",
    "    sum = 0\n",
    "    for element in group_dict[group]:\n",
    "        labels = bw.values(element['chr'], int(element['pos'] - (inputlen // 2)), int(element['pos'] + (inputlen // 2)))\n",
    "        labels = np.array(labels)\n",
    "        labels = np.nan_to_num(labels)\n",
    "        labels = np.sum(labels)\n",
    "        sum += labels\n",
    "    group_counts.append(sum)\n",
    "group_df = pd.DataFrame({'groups': groups, 'group_counts': group_counts})\n",
    "group_df.sort_values(by='group_counts', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold4': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_fold_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210000\n",
      "0\n",
      "80000\n",
      "200000\n",
      "150000\n",
      "140000\n",
      "60000\n",
      "40000\n",
      "120000\n",
      "90000\n",
      "70000\n",
      "170000\n",
      "20000\n",
      "130000\n",
      "110000\n",
      "50000\n",
      "10000\n",
      "160000\n",
      "190000\n",
      "180000\n",
      "30000\n",
      "100000\n",
      "Saving Splits\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2eebfcf45130>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mpeak_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ind'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_lst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'peak'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mnonpeak_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ind'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_lst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'nonpeak'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{args.output_path}/loci_{split}_indices_fold{fold}.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpeak_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwritelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "group_fold_dict = {}\n",
    "number_of_folds=5\n",
    "for fold in range(number_of_folds):\n",
    "    group_fold_dict[f\"fold{fold}\"]=[]\n",
    "\n",
    "count = 0\n",
    "valid_used = []\n",
    "\n",
    "for index,row in group_df.iterrows():\n",
    "    if index % 10000 == 0:\n",
    "        print(index)\n",
    "    if count % 2 == 0:\n",
    "        test_or_valid = 'valid'\n",
    "    else:\n",
    "        test_or_valid = 'test'\n",
    "    test_or_valid_fold = random.choice([i for i in range(number_of_folds) if i not in valid_used])\n",
    "    for fold in range(number_of_folds):\n",
    "        if fold != test_or_valid_fold:\n",
    "            group_fold_dict[f\"fold{fold}\"].append('train')\n",
    "        else:\n",
    "            group_fold_dict[f\"fold{fold}\"].append(test_or_valid)\n",
    "    count += 1\n",
    "    valid_used.append(test_or_valid_fold)\n",
    "    if len(valid_used) == number_of_folds:\n",
    "        valid_used = []\n",
    "\n",
    "\n",
    "for fold in range(number_of_folds):\n",
    "    group_df['fold' + str(fold)] = group_fold_dict['fold' + str(fold)]\n",
    "\n",
    "print(\"Saving Splits\")\n",
    "for fold in range(number_of_folds):\n",
    "    for split in ['valid','train','test']:\n",
    "        temp_lst = [group_dict.get(key) for key in group_df['groups'][group_df[f\"fold{fold}\"]==split]] \n",
    "        peak_indices = [i['ind'] for b in map(lambda x:[x] if not isinstance(x, list) else x, temp_lst) for i in b if i['group']=='peak']\n",
    "        nonpeak_indices = [i['ind'] for b in map(lambda x:[x] if not isinstance(x, list) else x, temp_lst) for i in b if i['group']=='nonpeak']\n",
    "        f = open(f\"{args.output_path}/loci_{split}_indices_fold{fold}.txt\", \"w\")\n",
    "        for items in peak_indices:\n",
    "            f.writelines(str(items)+'\\n')\n",
    "        f.close()\n",
    "        f = open(f\"{args.output_path}/background_{split}_indices_fold{fold}.txt\", \"w\")\n",
    "        for items in nonpeak_indices:\n",
    "            f.writelines(str(items)+'\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "peak_regions = pd.read_csv(args.peaks, sep='\\t', names=NARROWPEAK_SCHEMA)\n",
    "nonpeak_regions = pd.read_csv(args.nonpeaks, sep='\\t', names=NARROWPEAK_SCHEMA)\n",
    "\n",
    "print(\"Loading Data\")\n",
    "\n",
    "peak_chroms = peak_regions['chr']\n",
    "peak_pos = peak_regions['start'] + peak_regions['summit']\n",
    "\n",
    "nonpeak_chroms = nonpeak_regions['chr']\n",
    "nonpeak_pos = nonpeak_regions['start'] + nonpeak_regions['summit']\n",
    "\n",
    "all_chroms = peak_chroms.tolist() + nonpeak_chroms.tolist()\n",
    "all_pos = peak_pos.tolist() + nonpeak_pos.tolist()\n",
    "\n",
    "print(\"Creating Splits\")\n",
    "\n",
    "all_df = pd.DataFrame({'chr': all_chroms, 'pos': all_pos})\n",
    "all_df.sort_values(by=['chr', 'pos'], inplace=True)\n",
    "\n",
    "group_dict = {}\n",
    "\n",
    "cur_chrom = ''\n",
    "cur_group = ''\n",
    "last_pos = 0\n",
    "for index,row in all_df.iterrows():\n",
    "    if cur_chrom != '':\n",
    "        if row['chr'] != cur_chrom:\n",
    "            cur_chrom = row['chr']\n",
    "            cur_group += 1\n",
    "            group_dict[cur_group] = [(row['chr'], row['pos'])]\n",
    "        else:\n",
    "            if row['pos'] <= int(last_pos) + int(args.inputlen) + int(2 * args.max_jitter):\n",
    "                group_dict[cur_group].append((row['chr'], row['pos']))\n",
    "            else:\n",
    "                cur_group += 1\n",
    "                group_dict[cur_group] = [(row['chr'], row['pos'])]\n",
    "    else:\n",
    "        cur_chrom = row['chr']\n",
    "        cur_group = 0\n",
    "        group_dict[cur_group] = [(row['chr'], row['pos'])]\n",
    "    last_pos = row['pos']\n",
    "\n",
    "groups = []\n",
    "group_counts = []\n",
    "\n",
    "bw = pyBigWig.open(args.bigwig)\n",
    "\n",
    "for group in group_dict:\n",
    "    groups.append(group)\n",
    "    sum = 0\n",
    "    for element in group_dict[group]:\n",
    "        labels = bw.values(element[0], int(element[1] - (args.inputlen // 2)), int(element[1] + (args.inputlen // 2)))\n",
    "        labels = np.array(labels)\n",
    "        labels = np.nan_to_num(labels)\n",
    "        labels = np.sum(labels)\n",
    "        sum += labels\n",
    "    group_counts.append(sum)\n",
    "\n",
    "group_df = pd.DataFrame({'groups': groups, 'group_counts': group_counts})\n",
    "group_df.sort_values(by='group_counts', inplace=True)\n",
    "group_fold_dict = {'fold0': [], 'fold1': [], 'fold2': [], 'fold3': [], 'fold4': []}\n",
    "\n",
    "count = 0\n",
    "valid_used = []\n",
    "\n",
    "for index,row in group_df.iterrows():\n",
    "    if index % 10000 == 0:\n",
    "        print(index)\n",
    "    if count % 2 == 0:\n",
    "        test_or_valid = 'valid'\n",
    "    else:\n",
    "        test_or_valid = 'test'\n",
    "    test_or_valid_fold = random.choice([i for i in range(5) if i not in valid_used])\n",
    "    for fold in range(5):\n",
    "        if fold != test_or_valid_fold:\n",
    "            group_fold_dict['fold' + str(fold)].append('train')\n",
    "        else:\n",
    "            group_fold_dict['fold' + str(fold)].append(test_or_valid)\n",
    "    count += 1\n",
    "    valid_used.append(test_or_valid_fold)\n",
    "    if len(valid_used) == 5:\n",
    "        valid_used = []\n",
    "\n",
    "for fold in range(5):\n",
    "    group_df['fold' + str(fold)] = group_fold_dict['fold' + str(fold)]\n",
    "\n",
    "all_dict = {'chr': [], 'pos': [], 'fold0': [], 'fold1': [], 'fold2': [], 'fold3': [], 'fold4': []}\n",
    "\n",
    "for index,row in group_df.iterrows():\n",
    "    for element in group_dict[row['groups']]:\n",
    "        all_dict['chr'].append(element[0])\n",
    "        all_dict['pos'].append(element[1])\n",
    "        all_dict['fold0'].append(row['fold0'])\n",
    "        all_dict['fold1'].append(row['fold1'])\n",
    "        all_dict['fold2'].append(row['fold2'])\n",
    "        all_dict['fold3'].append(row['fold3'])\n",
    "        all_dict['fold4'].append(row['fold4'])\n",
    "\n",
    "splits_df = pd.DataFrame(all_dict)\n",
    "\n",
    "print(\"Saving Splits\")\n",
    "\n",
    "splits_df.to_csv(args.output_prefix + '.splits.tsv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basepairmodels_latest",
   "language": "python",
   "name": "basepairmodels_latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
